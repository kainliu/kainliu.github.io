<!-- home > archives > notes > about > posts (null)--><!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Find Similar Images Based On Locality Sensitive Hashing | Westworld</title><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Asar|Imprima"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/images/blog-logo.png"><link rel="apple-touch-icon" href="/images/blog-logo.png"><link rel="apple-touch-icon-precomposed" href="/images/blog-logo.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div id="header"><div class="body_container"><div class="site-name"><h1 class="hidden">Find Similar Images Based On Locality Sensitive Hashing</h1><a id="logo" href="/."><img src="/images/blog-logo.png" class="blog-logo nofancybox"><span>Westworld</span></a><p class="description"></p></div><div id="nav-menu"><a href="/"><i class="fa fa-rocket"> Home</i></a><a href="/archives/"><i class="fa fa-sitemap"> Archives</i></a><a href="/about/"><i class="fa fa-user-circle"> About</i></a></div></div></div><div id="layout" class="pure-g body_container"><div class="pure-u-1 pure-u-md-4-4"><div class="content_container"><div class="post"><div class="post-header"><div class="screen-wide-bg"><div class="post-header-container"><i class="post-thumbnail"><img src="/images/image-search.png" class="nofancybox"/></i><h1 class="post-title">Find Similar Images Based On Locality Sensitive Hashing</h1><div class="post-desc">A tutorial on hashing-powered searching for nearest neighbors.</div><div class="post-meta"><span class="author">Kai</span><span class="date">2016-04-01</span></div></div></div></div><div class="post-content"><p>Let’s start with the distribution of colors in a picture.</p>
<p>The color distribution reflects how the pixels are colored. In the space of <code>RGB</code>(red, green, blue), each pixel is represented by 24 bits (8 bits for red, 8 for green and 8 for blue). For example, given 8 bits to describe how red it is, there are 256 ($2^8$) different variations. In total, there are 16,777,216 ($256^3$) different kinds of <code>RGB</code> combinations, which already reaches <a href="https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29" target="_blank" rel="noopener">the limit of human eyes</a>.</p>
<p><img src="https://github.com/kainliu/Prism/raw/master/screenshot/bird.png?width=50" alt="A parrot on a tree. The right side is the RGB(red, green, blue) distribution."></p>
<p>To find similar images, the basic idea is that <strong>similar images share similar color distributions</strong>. To quantify similarities, it’s straightforward to make use of pixel counts to build up the profiles, which we call <code>signatures</code>.</p>
<h2 id="Signatures"><a href="#Signatures" class="headerlink" title="Signatures"></a>Signatures</h2><p>Let’s start with a simple example, assume that we partition each color into two categories:</p>
<ul>
<li><code>not-so-red</code> vs <code>red</code></li>
<li><code>not-so-green</code> vs <code>green</code></li>
<li><code>not-so-blue</code> vs <code>blue</code></li>
</ul>
<p><img src="/images/color-histogram-1.png" alt="2 segmentation of `RGB` colors"></p>
<p>All the pixels are partitioned into 8 ($2^3$) categories, and the pixel counts should be a list with 8 integers:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pixelCounts = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>For example, if the first pixel has a RGB value of (<code>150, 20, 30</code>), it be considered as (<code>red</code>, <code>not-so-green</code>, <code>not-so-blue</code>), and thus we increase the bucket <code>1,0,0</code> by 1.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pixelCounts[<span class="number">4</span>] += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>After walking through all the pixels in the image,</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pixelCounts = [<span class="number">0</span>, <span class="number">6197</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7336</span>, <span class="number">15</span>, <span class="number">4961</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>The list <code>pixelCounts</code> contains the information about color distributions, and we call it a <code>signature</code>.</p>
<p><img src="/images/color-histogram-2.png" alt="4 segmentation of `RGB` colors"></p>
<p>When we hash all colors into several buckets, it is intuitional to see similar colors in the same bucket. For example, <code>150, 20, 30</code> and <code>155, 22, 35</code> are very similar, so both of them are put into the same bucket.</p>
<p><img src="/images/color-histogram-3.png" alt="The pixel in RGB (`150, 20, 30`) is put into the bucket (`2,0,0`)"></p>
<p>If we increase the number of buckets, the signatures will be longer. For example, a 4-segmented signature contains 64 ($4^3$) integers.</p>
<p><img src="/images/bird-color-table.png?width=0.5" alt="The table shows the 4-segmented result of &lt;i&gt;A parrot on a tree&lt;/i&gt;. &lt;br/&gt; The vector of pixel counts (&lt;i&gt;#Pixels&lt;/i&gt;) is the signature."></p>
<h2 id="Similarities"><a href="#Similarities" class="headerlink" title="Similarities"></a>Similarities</h2><p>Now we extract a signature for every picture, the next job is to find how to measure the similarities between the signatures.</p>
<p><img src="/images/cosine-similarity.jpg" alt="Euclidean Distance `dist(A,B)` and Cosine Similarity `cos\theta`."></p>
<p><code>Cosine Similarity</code> is an inner product space that measures the cosine of the angle between them. The figure above illustrates that <code>Cosine Similarity</code> measures the angle between the vector space, compared to <code>Euclidean Distance</code> (a measure of the absolute distance between two points), more is to reflect differences in direction, but not the location.</p>
<p>If consider the signatures as 64-dimensional vectors, we could use <code>Cosine Similarity</code> to quantify their similarities.</p>
<h2 id="Locality-Sensitive-Hashing"><a href="#Locality-Sensitive-Hashing" class="headerlink" title="Locality Sensitive Hashing"></a>Locality Sensitive Hashing</h2><p><code>Locality Sensitive Hashing</code> (LSH) is an algorithm for searching near neighbors in high dimensional spaces. The core idea is to hash similar items into the same bucket. We will walk through the process of applying <strong>LSH for Cosine Similarity</strong>, with the help of the following plots from <a href="http://www.cs.jhu.edu/~vandurme/papers/VanDurmeLallACL10-slides.pdf" target="_blank" rel="noopener">Benjamin Van Durme &amp; Ashwin Lall, ACL2010</a>, with a few modifications by me.</p>
<p><img src="/images/cos-lsh-1.png?width=50" alt="Figure 1. Cosine Similarity LSH."></p>
<ol>
<li>In the Figure 1, there are two data points in red and yellow, representing two-dimensional data points. We are trying to find their cosine similarity using LSH.</li>
<li>The gray lines are randomly picked planes. Depending on whether the data point locates above or below a gray line, we mark this result as $1$ (above the line, in white) or $0$ (below the line, in black).</li>
<li>On the upper-left corner, there are two rows of white/black squares, representing the results of the two data points respectively.</li>
</ol>
<p><img src="/images/cos-lsh-2.png?width=50" alt="Figure 2. Cosine Similarity LSH."></p>
<ol>
<li>As in the example, we use 6 planes, and thus use 6 bits to represent each data. The length of sketch $b = 6$.</li>
<li>The hamming distance between the two hashed value $h = 1$.</li>
<li>The estimated cosine similarity is $cos(\frac{h}{b}\pi)$.</li>
</ol>
<p>These randomly picked planes are used as the buckets to hash the data points. We are able to estimate the cosine similarities from the hamming distances, the calculation of latter relatively more efficient.</p>
<p>Cosine Similarity is not sensitive to the magnitude of vectors. In some scenarios, people will apply <code>Adjusted Cosine Similarity</code> to reduce such sensitivity. Since the only concern here is to find whether the data points are located at the same side of the plane, there is no need to adjust the vectors, before calculating their similarities.</p>
<p>We can consider the pool of $k$ random planes playing the role of the hash function. Random planes are easy to generate, and highly efficient to apply in matrix.</p>
<h2 id="Sketches"><a href="#Sketches" class="headerlink" title="Sketches"></a>Sketches</h2><p>As we apply $k$ random planes to the whole dataset, each data point generates a $k$-bit vector, we call such vector as a <code>sketch</code>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> zeros, random, dot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sketch</span><span class="params">(M, k)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    M: the matrix of signatures.</span></span><br><span class="line"><span class="string">    k: random vector counts.</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    w,h = M.shape</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generating k random directions. use vectors</span></span><br><span class="line">    <span class="comment"># of normally distributed random numbers.</span></span><br><span class="line">    rd = random.randn(k, h)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># init sketches</span></span><br><span class="line">    sketches = zeros((k, w))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># for each random plane</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment"># for each signature</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(w):</span><br><span class="line">            <span class="comment"># whether the data point is above the random plane</span></span><br><span class="line">            v = dot(rd[i], M[j])</span><br><span class="line">            <span class="keyword">if</span> v &gt; <span class="number">0</span>:</span><br><span class="line">                sketch = <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> v &lt; <span class="number">0</span>:</span><br><span class="line">                sketch = <span class="number">0</span></span><br><span class="line">            <span class="comment"># v == 0 is of a tiny probability, choose 1 or 0 randomly</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> random.random() &gt;= <span class="number">0.5</span>:</span><br><span class="line">                    sketch = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    sketch = <span class="number">0</span></span><br><span class="line">            sketches[i][j] = sketch</span><br><span class="line">    <span class="keyword">return</span> sketches</span><br></pre></td></tr></table></figure>
<p><img src="/images/lsh-matrix-1.png" alt="Figure 1. Matrices of Signatures, LSH, and Skethes."></p>
<p>Let’s walk through all these steps before moving to the nearest neighbors:</p>
<ul>
<li>Signature<ul>
<li>The image dataset contains $N$ pictures. (e.g, $N = 100,000$)</li>
<li>Color spaces are cut into $b$ buckets. (e.g, $b = 64$)</li>
<li>Each signature thus consists of $b$ integers.</li>
<li><strong>The shape of signature matrix</strong> is <code>N * b</code>. ($N$ rows, $b$ columns)</li>
</ul>
</li>
</ul>
<ul>
<li>LSH<ul>
<li>The LSH family contains $k$ random vectors. (e.g, $k = 256$)</li>
<li>Each random vector is of $b$ dimension, abd thus has $b$ random floats.  </li>
<li><strong>The shape of random vector matrix</strong> is <code>k * b</code>.</li>
</ul>
</li>
</ul>
<ul>
<li>Sketch  <ul>
<li>For each random plane, calculate whether the data points are above it.</li>
<li>Entries of the sketch matrix are binary.</li>
<li><strong>The shape of sketch matrix</strong> is <code>k * N</code>.</li>
</ul>
</li>
</ul>
<h2 id="Nearest-Neighbors"><a href="#Nearest-Neighbors" class="headerlink" title="Nearest Neighbors"></a>Nearest Neighbors</h2><p>In order to find the nearest neighbors for a given picture, we can calculate the hamming distance in naive loops.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nested_loop</span><span class="params">(sketches, line)</span>:</span></span><br><span class="line">    <span class="string">'''Naive method to calculate hamming distance'''</span></span><br><span class="line">    h,w = sketches.shape</span><br><span class="line">    r = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, w):</span><br><span class="line">        intersection = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">0</span>, h):</span><br><span class="line">            <span class="keyword">if</span> sketches[k][i] == sketches[k][line]:</span><br><span class="line">                    intersection += <span class="number">1</span></span><br><span class="line">        r.append(round(</span><br><span class="line">            float(intersection) / float(w),</span><br><span class="line">            <span class="number">4</span></span><br><span class="line">        ))</span><br><span class="line">    <span class="keyword">return</span> r</span><br></pre></td></tr></table></figure>
<p>The naive method uses <code>nested loop</code> to calculate hamming distance, which causes inefficiency for big matrices.</p>
<p>It’s intuitive to use matrix-friendly method since we could have millions pictures.</p>
<p><img src="/images/lsh-matrix-2.png" alt="Figure 2. Scores."></p>
<p>A better method is to select the corresponding row of transposed sketch matrix, which stands for the binary relations between the given picture and $k$ random planes.<br>Then calculate dot product of picture sketch <code>1 * k</code> and matrix <code>k * N</code>, which is a <code>1 * N</code> array of integers.<br>We would like to make this <code>1 * N</code> array, highly correlated to the collection of hamming distances between the given picture and all.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a1 = np.array([ <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b1 = np.array([ <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a1 ^ b1</span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"><span class="comment"># the hamming distance between a1 and b1 is 2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sum(a1 ^ b1)</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="comment"># min distance is 0, and max is 4</span></span><br></pre></td></tr></table></figure>
<p>To speed up the calculation, we replace all $0$ with $-1$.<br>Since,<br>$$ (-1) * (-1) = 1 * 1 = 1 $$<br>And,<br>$$ 1 * (-1) = (-1) * 1 = -1 $$<br>The dot product of new sketch will be an integer between $[-k, k]$.<br>Higher dot product indicates higher similarity, because each similar part contributes $1$ to the result and dissimilar one contributes $-1$.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a2 = np.array([<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>,<span class="number">-1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b2 = np.array([ <span class="number">1</span>,<span class="number">-1</span>, <span class="number">1</span>,<span class="number">-1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dot(a2, b2)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="comment"># (-1)*1 + 1*(-1) + 1*1 + (-1)*(-1) = 0.</span></span><br><span class="line"><span class="comment"># min dot is -4, and max is 4</span></span><br></pre></td></tr></table></figure>
<p>It’s easy to prove that <code>Dot Product</code>(<code>DP</code>) is directly proportional to the <code>Hamming Distance</code>(<code>HD</code>):</p>
<p>$$ DP_{A,B} = Sketch_A * Sketch_B’ = N_{same} - N_{diff} $$</p>
<p>Since, $$ N_{same} + N_{diff} = k $$</p>
<p>Finally, $$ HD_{A,B} = \frac{N_{same}}{k} = \frac{ DP_{A,B} + k }{2} * \frac {1}{k} = \frac{DP_{A,B}}{2k} + \frac{1}{2} $$</p>
<p>The function is as follows:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">similar</span><span class="params">(sketches, line)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transpose_dot</span><span class="params">(sketches, line)</span>:</span></span><br><span class="line">        result = dot(sketches.transpose()[line], sketches)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    scores = transpose_dot(sketches)</span><br><span class="line"></span><br><span class="line">    n = <span class="number">20</span></span><br><span class="line">    top_n = argsort(scores)[-n:][::<span class="number">-1</span>]</span><br><span class="line">    <span class="comment">#       argsort(scores)[-n:]       # last n elements</span></span><br><span class="line">    <span class="comment">#                           [::-1] # reverse to get top N lines</span></span><br><span class="line">    <span class="keyword">return</span> top_n</span><br></pre></td></tr></table></figure>
<p>By reversing the list of scores, we select best $n$ candidates according to descending scores.</p>
<h2 id="Tuning-Parameters"><a href="#Tuning-Parameters" class="headerlink" title="Tuning Parameters"></a>Tuning Parameters</h2><p>Tuning parameters to find the optimum balance between accuracy and efficiency is important in the implementation.</p>
<p>For example, in general, the <code>r-squared</code> of sketch similarity and signature similarity rises with number of vectors. More random vectors can provide better estimation of the similarity, but at the same time cost more time and memory. Thus experiments are carried out as follows:</p>
<p><img src="https://github.com/kainliu/Prism/raw/master/screenshot/vectors-n.jpg?width=50" alt="Experiments of tuning the number of random vectors. "></p>
<p>From the above graphs, we can select $k=256$ to get a r-squared greater than $0.9$ while keeping efficiency.</p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>I made a side project called <a href="https://github.com/kainliu/Prism" target="_blank" rel="noopener">Prism</a>.<br>Prism provides a web-based interface to explain the process from extracting features to searching nearest neighbors.<br>It contains not only the implementation of above algorithms, also uses a dataset with 24,000 pictures as a full-function demo.</p>
<p>All the source codes, datasets, results and analysis are in the github repository <a href="https://github.com/kainliu/Prism" target="_blank" rel="noopener">github.com/kainliu/Prism</a>.</p>
<table>
<thead>
<tr>
<th>1</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://github.com/kainliu/Prism/raw/master/screenshot/prism-page-001.jpg" alt="Prism provides a web-based interface presenting the process."></td>
<td><img src="https://github.com/kainliu/Prism/raw/master/screenshot/prism-page-002.jpg" alt="The signature of the chosen picture will be plotted."></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>3</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://github.com/kainliu/Prism/raw/master/screenshot/prism-page-003.jpg" alt="The sketch is plotted in a fan chart. "></td>
<td><img src="https://raw.githubusercontent.com/kainliu/Prism/master/screenshot/prism-page-004.jpg" alt="The nearest neighbors of chosen picture."></td>
</tr>
</tbody>
</table>
<h2 id="Experiements"><a href="#Experiements" class="headerlink" title="Experiements"></a>Experiements</h2><table>
<thead>
<tr>
<th>1</th>
<th>2</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/images/prism-demo-1.png" alt=""></td>
<td><img src="/images/prism-demo-2.png" alt=""></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>3</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/images/prism-demo-3.png" alt=""></td>
<td><img src="/images/prism-demo-4.png" alt=""></td>
</tr>
</tbody>
</table>
<p>As we seen from the above results - nearest neighbors have similar colors - which basically fits our original idea.</p>
<h2 id="Wrapping-Up"><a href="#Wrapping-Up" class="headerlink" title="Wrapping Up"></a>Wrapping Up</h2><p>It’s a meaningful trial for me, to starting from an idea to presenting a viable tool.</p>
<p>However, this method is highly influenced by the diversity of colors. For example, the 4th experiment mixed the pictures of white cups with the baseballs, since they share a large percentage of similar white colors.</p>
<p>To overcome this shortcoming, an option is to take boundaries of the objects into account. There are many popular algorithms in <a href="https://en.wikipedia.org/wiki/Edge_detection" target="_blank" rel="noopener">contour/edge detection</a>.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/%C3%84%C3%A4retuvastuse_n%C3%A4ide.png/1000px-%C3%84%C3%A4retuvastuse_n%C3%A4ide.png" width="50%" alt="Edge detection example. From wikipedia."></p>
</div><div class="post-meta"><div class="tags"><a href="/tags/fingerprint/">fingerprint</a><a href="/tags/algorithm/">algorithm</a><a href="/tags/python/">python</a><a href="/tags/similarity/">similarity</a><!-- tag.name--></div></div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><div><a data-url="http://westworld.name/posts/find-similar-images-based-on-locality-sensitive-hashing/" data-id="cjkq38byr00115iqbdlt5nxic" class="article-share-link">Share</a></div><div id="disqus_show" class="readmore"><a class="show-comments" href="javascript:return false;"><span class="disqus-comment-count" data-disqus-identifier="posts/find-similar-images-based-on-locality-sensitive-hashing/"> Comments</span></a></div><div id="disqus_thread"></div><script>// Requires jQuery of course.
$(document).ready(function() {
    $('.show-comments').on('click', function(){
        var disqus_shortname = 'kaigithub';
        // ajax request to load the disqus javascript
        $.ajax({
                type: "GET",
                url: "//" + disqus_shortname + ".disqus.com/embed.js",
                dataType: "script",
                cache: true
        });
        // hide the button once comments load
        $(this).fadeOut();
    });
});
</script><script id="dsq-count-scr" src="//kaigithub.disqus.com/count.js" async></script><div id="post_nav_container" class="screen-wide-bg">  <div class="post-nav pure-u-1 pure-u-md-4-4"><div class="pure-u-md-1-2"><a href="/posts/on-promise/" class="pre"><span>On Promise</span><i><img src="/images/food/coffee-3.png" class="nofancybox"/></i></a></div><div class="pure-u-md-1-2"> <a href="/posts/behind-a-random-string-generator/" class="next"><span>Behind A Random String Generator</span><i><img src="/images/coin.png" class="nofancybox"></i></a></div></div></div></div></div></div><div class="pure-u-1 pure-u-md-4-4"><div id="footer"><p>© <a href="/." rel="nofollow">Westworld.</a><span> Site Generated by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo. </a></span></p><p> <span> Theme modified from <a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo">Maupassant. </a></span><span>Icons from <a rel="nofollow" target="_blank" href="http://www.flaticon.com">Flaticon </a>are licensed by CC 3.0 BY.</span></p></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    preview: "none"
  }
});
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></body></html>